# 훈련 파라미터 가이드

이 문서는 `train.py` 스크립트에서 사용할 수 있는 모든 훈련 파라미터를 설명합니다.

## 목차
1. [기본 파라미터](#기본-파라미터)
2. [모델 파라미터](#모델-파라미터)
3. [데이터셋 파라미터](#데이터셋-파라미터)
4. [훈련 파라미터](#훈련-파라미터)
5. [시각화 및 저장 파라미터](#시각화-및-저장-파라미터)
6. [기타 파라미터](#기타-파라미터)
7. [pix2pix 모델 전용 파라미터](#pix2pix-모델-전용-파라미터)

---

## 기본 파라미터

### `--dataroot` (필수)
- **타입**: 문자열
- **기본값**: 없음 (필수)
- **설명**: 이미지 데이터셋의 경로. 하위 폴더로 `trainA`, `trainB`, `valA`, `valB` 등을 포함해야 합니다.
- **예시**: `--dataroot ./portrait_retouch`

### `--name`
- **타입**: 문자열
- **기본값**: `"experiment_name"`
- **설명**: 실험 이름. 샘플과 모델이 저장될 위치를 결정합니다.
- **예시**: `--name portrait_retouch_reverse`

### `--checkpoints_dir`
- **타입**: 문자열
- **기본값**: `"./checkpoints"`
- **설명**: 모델 체크포인트가 저장될 디렉토리 경로
- **예시**: `--checkpoints_dir ./checkpoints`

---

## 모델 파라미터

### `--model`
- **타입**: 문자열
- **기본값**: `"cycle_gan"`
- **선택값**: `cycle_gan` | `pix2pix` | `test` | `colorization`
- **설명**: 사용할 모델을 선택합니다.
- **예시**: `--model pix2pix`

### `--input_nc`
- **타입**: 정수
- **기본값**: `3`
- **설명**: 입력 이미지의 채널 수. RGB는 3, 그레이스케일은 1
- **예시**: `--input_nc 3`

### `--output_nc`
- **타입**: 정수
- **기본값**: `3`
- **설명**: 출력 이미지의 채널 수. RGB는 3, 그레이스케일은 1
- **예시**: `--output_nc 3`

### `--ngf`
- **타입**: 정수
- **기본값**: `64`
- **설명**: 생성기(Generator)의 마지막 컨볼루션 레이어에서 사용하는 필터 수
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 128, 256)**: 모델 용량과 표현력 증가, 더 복잡한 변환 학습 가능, 메모리 사용량 증가, 훈련 시간 증가
  - **값 감소 (예: 32)**: 모델 용량 감소, 메모리 절약, 빠른 훈련, 표현력 제한 가능
  - **권장**: 고해상도 이미지(1024x1024 이상)나 복잡한 변환에는 128-256, 일반적인 경우 64 유지
- **예시**: `--ngf 64`

### `--ndf`
- **타입**: 정수
- **기본값**: `64`
- **설명**: 판별기(Discriminator)의 첫 번째 컨볼루션 레이어에서 사용하는 필터 수
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 128, 256)**: 판별기 성능 향상, 더 정확한 진위 판별, 생성기 훈련 난이도 증가, 메모리 사용량 증가
  - **값 감소 (예: 32)**: 판별기 성능 감소, 생성기 훈련이 쉬워지지만 품질 저하 가능
  - **권장**: 일반적으로 `--ngf`와 동일한 값 사용. 생성기와 판별기 균형 유지
- **예시**: `--ndf 64`

### `--netD`
- **타입**: 문자열
- **기본값**: `"basic"`
- **선택값**: `basic` | `n_layers` | `pixel`
- **설명**: 판별기 아키텍처를 지정합니다. `basic`은 70x70 PatchGAN입니다. `n_layers`는 판별기의 레이어 수를 지정할 수 있습니다.
- **효과 및 사용 시나리오**:
  - **`basic`**: 70x70 PatchGAN, 가장 일반적, 빠른 훈련, 대부분의 경우에 적합
  - **`n_layers`**: 레이어 수를 `--n_layers_D`로 조절 가능, 더 깊은 네트워크로 세밀한 판별 가능, 메모리 사용량 증가
  - **`pixel`**: 픽셀 단위 판별, 매우 세밀한 판별 가능, 메모리 사용량 크게 증가, 고품질 생성에 유용
  - **권장**: 일반적으로 `basic` 사용. 고해상도나 매우 세밀한 변환이 필요할 때 `n_layers` 또는 `pixel` 고려
- **예시**: `--netD basic`

### `--netG`
- **타입**: 문자열
- **기본값**: `"resnet_9blocks"` (pix2pix는 `"unet_256"`)
- **선택값**: `resnet_9blocks` | `resnet_6blocks` | `unet_256` | `unet_128`
- **설명**: 생성기 아키텍처를 지정합니다.
- **효과 및 사용 시나리오**:
  - **`unet_256`**: 256x256 이미지용 U-Net, pix2pix 기본값, 스킵 커넥션으로 세부 정보 보존에 우수
  - **`unet_128`**: 128x128 이미지용 U-Net, 더 빠른 훈련, 메모리 절약, 낮은 해상도에 적합
  - **`resnet_9blocks`**: 9개 ResNet 블록, CycleGAN 기본값, 깊은 네트워크로 복잡한 변환 학습 가능
  - **`resnet_6blocks`**: 6개 ResNet 블록, 더 빠른 훈련, 메모리 절약, 간단한 변환에 적합
  - **권장**: pix2pix는 `unet_256`, CycleGAN은 `resnet_9blocks` 사용. 메모리 부족 시 `resnet_6blocks` 또는 `unet_128` 고려
- **예시**: `--netG unet_256`

### `--n_layers_D`
- **타입**: 정수
- **기본값**: `3`
- **설명**: `--netD n_layers`를 사용할 때만 적용됩니다. 판별기의 레이어 수를 지정합니다.
- **예시**: `--n_layers_D 3`

### `--norm`
- **타입**: 문자열
- **기본값**: `"instance"` (pix2pix는 `"batch"`)
- **선택값**: `instance` | `batch` | `none` | `syncbatch`
- **설명**: 정규화 방법을 선택합니다. 인스턴스 정규화 또는 배치 정규화
- **효과 및 사용 시나리오**:
  - **`batch`**: 배치 정규화, pix2pix 기본값, 배치 통계 사용, 배치 크기가 클 때 안정적, 페어 데이터에 적합
  - **`instance`**: 인스턴스 정규화, CycleGAN 기본값, 각 이미지 독립적으로 정규화, 스타일 변환에 적합, 배치 크기 1에서도 안정적
  - **`none`**: 정규화 없음, 간단한 모델, 빠른 훈련, 불안정할 수 있음
  - **`syncbatch`**: 동기화 배치 정규화, 분산 훈련에 사용, 여러 GPU 사용 시 효과적
  - **권장**: pix2pix는 `batch`, CycleGAN은 `instance` 사용. 배치 크기 1일 때는 `instance` 권장
- **예시**: `--norm batch`

### `--init_type`
- **타입**: 문자열
- **기본값**: `"normal"`
- **선택값**: `normal` | `xavier` | `kaiming` | `orthogonal`
- **설명**: 네트워크 초기화 방법을 선택합니다.
- **효과 및 사용 시나리오**:
  - **`normal`**: 정규 분포 초기화, 기본값, 대부분의 경우 잘 작동, `--init_gain`으로 스케일 조절
  - **`xavier`**: Xavier 초기화, 시그모이드/하이퍼볼릭 탄젠트 활성화 함수에 적합, 안정적인 훈련
  - **`kaiming`**: Kaiming 초기화, ReLU 활성화 함수에 적합, 깊은 네트워크에서 유용
  - **`orthogonal`**: 직교 행렬 초기화, 그래디언트 소실/폭발 완화, 안정적인 훈련
  - **권장**: 일반적으로 `normal` 유지. 훈련 불안정 시 `xavier` 또는 `kaiming` 시도
- **예시**: `--init_type normal`

### `--init_gain`
- **타입**: 실수
- **기본값**: `0.02`
- **설명**: `normal`, `xavier`, `orthogonal` 초기화 방법에 사용되는 스케일링 팩터
- **예시**: `--init_gain 0.02`

### `--no_dropout`
- **타입**: 플래그 (값 없음)
- **기본값**: False
- **설명**: 지정하면 생성기에 드롭아웃을 사용하지 않습니다.
- **예시**: `--no_dropout`

---

## 데이터셋 파라미터

### `--dataset_mode`
- **타입**: 문자열
- **기본값**: `"unaligned"` (pix2pix는 `"aligned"`)
- **선택값**: `unaligned` | `aligned` | `single` | `colorization`
- **설명**: 데이터셋 로드 방식을 선택합니다.
  - `aligned`: 정렬된 페어 데이터 (pix2pix에 사용)
  - `unaligned`: 정렬되지 않은 데이터 (CycleGAN에 사용)
  - `single`: 단일 이미지 데이터셋
  - `colorization`: 컬러화 데이터셋
- **예시**: `--dataset_mode aligned`

### `--direction`
- **타입**: 문자열
- **기본값**: `"AtoB"`
- **선택값**: `AtoB` | `BtoA`
- **설명**: 변환 방향을 지정합니다. A에서 B로 또는 B에서 A로
- **예시**: `--direction AtoB`

### `--serial_batches`
- **타입**: 플래그 (값 없음)
- **기본값**: False
- **설명**: True로 설정하면 배치를 만들 때 이미지를 순서대로 가져옵니다. False면 무작위로 가져옵니다.
- **효과 및 사용 시나리오**:
  - **사용 안 함 (기본값)**: 무작위 배치, 일반적인 훈련에 적합, 데이터 다양성 향상, 더 나은 일반화
  - **사용 (`--serial_batches`)**: 순차적 배치, 재현 가능한 결과, 디버깅에 유용, 일반화 성능 감소 가능
  - **권장**: 일반적으로 사용 안 함. 재현성 테스트나 디버깅 시에만 사용
- **예시**: `--serial_batches`

### `--num_threads`
- **타입**: 정수
- **기본값**: `4`
- **설명**: 데이터 로딩에 사용할 스레드 수
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 8, 16)**: 더 빠른 데이터 로딩, CPU 사용량 증가, GPU 대기 시간 감소, 메모리 사용량 증가
  - **값 감소 (예: 1, 2)**: 메모리 절약, 느린 데이터 로딩, GPU 유휴 시간 증가
  - **권장**: CPU 코어 수에 따라 조절. 4-8 코어는 4-8, 8+ 코어는 8-16 권장. GPU가 자주 대기하면 증가
- **예시**: `--num_threads 4`

### `--batch_size`
- **타입**: 정수
- **기본값**: `1`
- **설명**: 입력 배치 크기
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 4, 8, 16)**: 더 안정적인 그래디언트, 배치 정규화 효과 향상, 빠른 수렴 가능, 메모리 사용량 크게 증가
  - **값 감소 (1)**: 메모리 절약, GPU 메모리 부족 시 필수, 배치 정규화 효과 감소
  - **권장**: GPU 메모리에 따라 조절. 6GB GPU는 1-2, 12GB는 4-8, 24GB 이상은 8-16 권장
- **예시**: `--batch_size 1`

### `--load_size`
- **타입**: 정수
- **기본값**: `286`
- **설명**: 이미지를 이 크기로 스케일링합니다.
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 512, 1024, 2048)**: 더 높은 해상도 학습, 세부 정보 보존, 메모리 사용량 크게 증가, 훈련 시간 증가
  - **값 감소 (예: 128, 256)**: 메모리 절약, 빠른 훈련, 세부 정보 손실 가능
  - **권장**: GPU 메모리에 따라 조절. 6GB GPU는 256-512, 12GB는 512-1024, 24GB 이상은 1024-2048 가능
- **예시**: `--load_size 1024`

### `--crop_size`
- **타입**: 정수
- **기본값**: `256`
- **설명**: 스케일링 후 이 크기로 크롭합니다.
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 512, 1024)**: 더 큰 영역 학습, 전체적인 맥락 파악 향상, 메모리 사용량 증가
  - **값 감소 (예: 128, 256)**: 메모리 절약, 빠른 훈련, 큰 객체/맥락 학습 어려움
  - **권장**: 일반적으로 `load_size`보다 작게 설정. `load_size`와 동일하게 설정하면 크롭 없이 리사이즈만 수행
- **예시**: `--crop_size 1024`

### `--max_dataset_size`
- **타입**: 정수
- **기본값**: 무한대 (`float("inf")`)
- **설명**: 데이터셋당 허용되는 최대 샘플 수. 이 값보다 많은 이미지가 있으면 일부만 로드됩니다.
- **예시**: `--max_dataset_size 1000`

### `--preprocess`
- **타입**: 문자열
- **기본값**: `"resize_and_crop"`
- **선택값**: `resize_and_crop` | `crop` | `scale_width` | `scale_width_and_crop` | `none`
- **설명**: 로드 시 이미지의 스케일링 및 크롭 방법을 지정합니다.
- **효과 및 사용 시나리오**:
  - **`resize_and_crop`**: 이미지를 `load_size`로 리사이즈 후 `crop_size`로 크롭, 기본값, 정사각형 이미지 생성, 가장 일반적
  - **`scale_width`**: 너비만 `load_size`로 스케일, 종횡비 유지, 종횡비 보존이 중요한 경우 사용
  - **`scale_width_and_crop`**: 너비 스케일 후 크롭, 종횡비 부분 보존, 고해상도 이미지에 유용
  - **`crop`**: 크롭만 수행, 원본 크기 유지 가능, 이미 충분히 큰 이미지에 사용
  - **`none`**: 전처리 없음, 원본 이미지 사용, 이미 정제된 데이터에 사용
  - **권장**: 일반적으로 `resize_and_crop`. 종횡비 보존이 중요하면 `scale_width` 또는 `scale_width_and_crop` 사용
- **예시**: `--preprocess resize_and_crop`

### `--no_flip`
- **타입**: 플래그 (값 없음)
- **기본값**: False
- **설명**: 지정하면 데이터 증강을 위한 이미지 뒤집기를 수행하지 않습니다.
- **효과 및 사용 시나리오**:
  - **사용 안 함 (기본값)**: 수평 뒤집기 데이터 증강 수행, 데이터셋 크기 효과적 증가, 방향성 있는 이미지(텍스트, 로고 등)에는 부적합
  - **사용 (`--no_flip`)**: 뒤집기 없음, 원본 방향 유지, 방향성이 중요한 이미지에 필수, 데이터 증강 효과 감소
  - **권장**: 일반적으로 뒤집기 사용. 인물 사진, 건축물, 텍스트가 포함된 이미지는 `--no_flip` 사용
- **예시**: `--no_flip`

---

## 훈련 파라미터

### `--n_epochs`
- **타입**: 정수
- **기본값**: `100`
- **설명**: 초기 학습률로 훈련할 에포크 수
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 200, 500, 1000)**: 더 긴 훈련, 더 나은 결과 가능, 과적합 위험, 훈련 시간 증가
  - **값 감소 (예: 50)**: 빠른 훈련, 조기 종료 가능, 충분한 학습 부족 가능
  - **권장**: 데이터셋 크기와 복잡도에 따라 조절. 작은 데이터셋(100-500장)은 200-500, 큰 데이터셋(1000+장)은 100-200 권장
- **예시**: `--n_epochs 200`

### `--n_epochs_decay`
- **타입**: 정수
- **기본값**: `100`
- **설명**: 학습률을 0으로 선형 감소시킬 에포크 수
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 200, 500)**: 더 긴 학습률 감소 기간, 세밀한 조정 가능, 느린 수렴
  - **값 감소 (예: 50)**: 빠른 학습률 감소, 빠른 수렴, 조기 종료 가능
  - **권장**: 일반적으로 `n_epochs`와 동일하게 설정. 부드러운 수렴을 원하면 `n_epochs`보다 크게 설정
- **예시**: `--n_epochs_decay 200`

### `--beta1`
- **타입**: 실수
- **기본값**: `0.5`
- **설명**: Adam 옵티마이저의 모멘텀 항
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 0.7, 0.9)**: 더 강한 모멘텀, 빠른 수렴, 불안정할 수 있음, 진동 가능
  - **값 감소 (예: 0.3, 0.1)**: 약한 모멘텀, 안정적인 학습, 느린 수렴
  - **권장**: 일반적으로 0.5 유지. GAN 훈련에서는 0.5가 표준. 다른 작업에서는 0.9도 사용 가능
- **예시**: `--beta1 0.5`

### `--lr`
- **타입**: 실수
- **기본값**: `0.0002`
- **설명**: Adam 옵티마이저의 초기 학습률
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 0.001, 0.002)**: 빠른 학습, 불안정할 수 있음, 발산 가능성, 초기 훈련 속도 향상
  - **값 감소 (예: 0.0001, 0.00005)**: 안정적인 학습, 느린 수렴, 세밀한 조정 가능, 고품질 결과 가능
  - **권장**: 일반적으로 0.0002 유지. 불안정하면 0.0001로 감소, 느린 수렴 시 0.0005까지 증가 가능
- **예시**: `--lr 0.0002`

### `--gan_mode`
- **타입**: 문자열
- **기본값**: `"lsgan"` (pix2pix는 `"vanilla"`)
- **선택값**: `vanilla` | `lsgan` | `wgangp`
- **설명**: GAN 목적 함수의 타입
- **효과 및 사용 시나리오**:
  - **`vanilla`**: 원본 GAN 논문의 교차 엔트로피 손실, pix2pix 기본값, 안정적, 간단한 구현
  - **`lsgan`**: Least Squares GAN, CycleGAN 기본값, 더 부드러운 그래디언트, 안정적인 훈련, 빠른 수렴
  - **`wgangp`**: Wasserstein GAN with Gradient Penalty, 가장 안정적, 고품질 생성, 느린 훈련, 메모리 사용량 증가
  - **권장**: pix2pix는 `vanilla`, CycleGAN은 `lsgan` 사용. 훈련 불안정 시 `wgangp` 시도
- **예시**: `--gan_mode vanilla`

### `--pool_size`
- **타입**: 정수
- **기본값**: `50` (pix2pix는 `0`)
- **설명**: 이전에 생성된 이미지를 저장하는 이미지 버퍼의 크기
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 100, 200)**: 더 많은 이전 이미지 저장, 판별기 훈련 안정화, 메모리 사용량 증가, CycleGAN에 유용
  - **값 감소 (0)**: 이미지 버퍼 사용 안 함, 메모리 절약, pix2pix 기본값, 페어 데이터에는 불필요
  - **권장**: pix2pix는 0 유지. CycleGAN은 50 사용. 훈련 불안정 시 100-200으로 증가
- **예시**: `--pool_size 0`

### `--lr_policy`
- **타입**: 문자열
- **기본값**: `"linear"`
- **선택값**: `linear` | `step` | `plateau` | `cosine`
- **설명**: 학습률 스케줄링 정책
- **효과 및 사용 시나리오**:
  - **`linear`**: 선형 감소, 기본값, `n_epochs_decay` 동안 선형적으로 0으로 감소, 예측 가능한 감소
  - **`step`**: 단계적 감소, `lr_decay_iters`마다 감소, 급격한 감소, 특정 시점에 조절 가능
  - **`plateau`**: 손실이 개선되지 않을 때 감소, 적응적 감소, 효율적인 학습, 조기 종료와 유사
  - **`cosine`**: 코사인 감소, 부드러운 감소 곡선, 자연스러운 수렴, 최근 연구에서 선호
  - **권장**: 일반적으로 `linear` 유지. 긴 훈련에는 `cosine`, 적응적 조절이 필요하면 `plateau` 사용
- **예시**: `--lr_policy linear`

### `--lr_decay_iters`
- **타입**: 정수
- **기본값**: `50`
- **설명**: `lr_policy`가 `step`일 때, 이 반복 횟수마다 gamma를 곱합니다.
- **예시**: `--lr_decay_iters 50`

### `--continue_train`
- **타입**: 플래그 (값 없음)
- **기본값**: False
- **설명**: 지정하면 훈련을 계속 진행합니다. 최신 모델을 로드합니다.
- **예시**: `--continue_train`

### `--epoch_count`
- **타입**: 정수
- **기본값**: `1`
- **설명**: 시작 에포크 카운트. 모델은 `<epoch_count>`, `<epoch_count>+<save_latest_freq>`, ... 에 저장됩니다.
- **예시**: `--epoch_count 1`

### `--phase`
- **타입**: 문자열
- **기본값**: `"train"`
- **설명**: 훈련, 검증, 테스트 등의 단계를 지정합니다.
- **예시**: `--phase train`

---

## 시각화 및 저장 파라미터

### `--display_freq`
- **타입**: 정수
- **기본값**: `400`
- **설명**: 화면에 훈련 결과를 표시하는 빈도 (반복 횟수)
- **예시**: `--display_freq 50`

### `--update_html_freq`
- **타입**: 정수
- **기본값**: `1000`
- **설명**: 훈련 결과를 HTML로 저장하는 빈도 (반복 횟수)
- **예시**: `--update_html_freq 1000`

### `--print_freq`
- **타입**: 정수
- **기본값**: `100`
- **설명**: 콘솔에 훈련 결과를 출력하는 빈도 (반복 횟수)
- **예시**: `--print_freq 10`

### `--no_html`
- **타입**: 플래그 (값 없음)
- **기본값**: False
- **설명**: 지정하면 중간 훈련 결과를 HTML로 저장하지 않습니다.
- **예시**: `--no_html`

### `--save_latest_freq`
- **타입**: 정수
- **기본값**: `5000`
- **설명**: 최신 결과를 저장하는 빈도 (반복 횟수)
- **예시**: `--save_latest_freq 5000`

### `--save_epoch_freq`
- **타입**: 정수
- **기본값**: `5`
- **설명**: 에포크 종료 시 체크포인트를 저장하는 빈도
- **예시**: `--save_epoch_freq 10`

### `--save_by_iter`
- **타입**: 플래그 (값 없음)
- **기본값**: False
- **설명**: 지정하면 반복 횟수별로 모델을 저장합니다.
- **예시**: `--save_by_iter`

### `--display_winsize`
- **타입**: 정수
- **기본값**: `256`
- **설명**: visdom과 HTML 모두에서 사용하는 디스플레이 창 크기
- **예시**: `--display_winsize 256`

---

## 기타 파라미터

### `--epoch`
- **타입**: 문자열
- **기본값**: `"latest"`
- **설명**: 로드할 에포크를 지정합니다. `latest`로 설정하면 최신 캐시된 모델을 사용합니다.
- **예시**: `--epoch latest`

### `--load_iter`
- **타입**: 정수
- **기본값**: `0`
- **설명**: 로드할 반복 횟수. `load_iter > 0`이면 `iter_[load_iter]`로 모델을 로드하고, 그렇지 않으면 `[epoch]`로 로드합니다.
- **예시**: `--load_iter 0`

### `--verbose`
- **타입**: 플래그 (값 없음)
- **기본값**: False
- **설명**: 지정하면 더 많은 디버깅 정보를 출력합니다.
- **예시**: `--verbose`

### `--suffix`
- **타입**: 문자열
- **기본값**: `""`
- **설명**: 사용자 정의 접미사. `opt.name = opt.name + suffix` 형식으로 사용됩니다. 예: `{model}_{netG}_size{load_size}`
- **예시**: `--suffix "_test"`

### `--use_wandb`
- **타입**: 플래그 (값 없음)
- **기본값**: False
- **설명**: 지정하면 wandb 로깅을 초기화합니다.
- **예시**: `--use_wandb`

### `--wandb_project_name`
- **타입**: 문자열
- **기본값**: `"CycleGAN-and-pix2pix"`
- **설명**: wandb 프로젝트 이름을 지정합니다.
- **예시**: `--wandb_project_name my_project`

---

## pix2pix 모델 전용 파라미터

### `--lambda_L1`
- **타입**: 실수
- **기본값**: `100.0`
- **설명**: L1 손실의 가중치. 훈련 목적 함수는 `GAN Loss + lambda_L1 * ||G(A)-B||_1`입니다.
- **효과 및 사용 시나리오**:
  - **값 증가 (예: 200, 500, 1000)**: 더 정확한 픽셀 매칭, 선명한 결과, 색상 보존 향상, 생성 다양성 감소 가능
  - **값 감소 (예: 50, 10)**: 더 다양한 생성, GAN 손실 영향 증가, 부드러운 결과, 픽셀 정확도 감소 가능
  - **권장**: 일반적으로 100.0 유지. 흐릿한 결과가 나오면 200-500으로 증가, 과도하게 정확하지만 다양성이 부족하면 50-80으로 감소
- **예시**: `--lambda_L1 100.0`

---

## 사용 예시

### 기본 pix2pix 훈련
```bash
python train.py ^
  --dataroot ./portrait_retouch ^
  --name portrait_retouch_reverse ^
  --model pix2pix ^
  --direction AtoB ^
  --batch_size 1 ^
  --load_size 1024 ^
  --crop_size 1024 ^
  --n_epochs 200 ^
  --n_epochs_decay 200
```

### 훈련 재개 (continue_train)
```bash
python train.py ^
  --dataroot ./portrait_retouch ^
  --name portrait_retouch_reverse ^
  --model pix2pix ^
  --direction AtoB ^
  --continue_train ^
  --batch_size 1 ^
  --load_size 1024 ^
  --crop_size 1024 ^
  --n_epochs 200 ^
  --n_epochs_decay 200
```

### 고해상도 훈련 (더 큰 배치 크기)
```bash
python train.py ^
  --dataroot ./portrait_retouch ^
  --name portrait_retouch_reverse ^
  --model pix2pix ^
  --direction AtoB ^
  --batch_size 4 ^
  --load_size 512 ^
  --crop_size 512 ^
  --n_epochs 100 ^
  --n_epochs_decay 100 ^
  --display_freq 50 ^
  --print_freq 10
```

---

## 참고사항

1. **Windows CMD 사용 시**: 줄 연속 문자로 백슬래시(`\`) 대신 캐럿(`^`)을 사용해야 합니다.
2. **pix2pix 기본값**: pix2pix 모델을 사용하면 일부 파라미터의 기본값이 자동으로 변경됩니다:
   - `--norm`: `batch`
   - `--netG`: `unet_256`
   - `--dataset_mode`: `aligned`
   - `--pool_size`: `0`
   - `--gan_mode`: `vanilla`
3. **메모리 부족 시**: `--batch_size`를 줄이거나 `--load_size`와 `--crop_size`를 낮추세요.
4. **훈련 속도 향상**: `--num_threads`를 증가시키고 `--display_freq`와 `--print_freq`를 줄이세요.

